import cv2
import mediapipe as mp
import pyautogui
import numpy as np

def run_gaze_estimation(q, show_face_mesh=False, stop_event=None):
    screen_w, screen_h = pyautogui.size()   # í˜„ì¬ ëª¨ë‹ˆí„° í•´ìƒë„
    cap = cv2.VideoCapture(0)               # ë…¸íŠ¸ë¶ ì¹´ë©”ë¼ ìº¡ì³
    print(f"Gaze Estimation, Camera resolution: {cap.get(cv2.CAP_PROP_FRAME_WIDTH)} x {cap.get(cv2.CAP_PROP_FRAME_HEIGHT)}")

    mp_face_mesh = mp.solutions.face_mesh                       # ì–¼êµ´ ì¸ì‹ í´ë˜ìŠ¤
    face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)    # ì–¼êµ´ ë©”ì‰¬ ì¤‘ refine_landmarks ë°˜ì˜(í™ì±„)

    if show_face_mesh:        # ì–¼êµ´ ë©”ì‰¬ ë¶ˆëŸ¬ì˜¬ ë•Œ
        mp_drawing = mp.solutions.drawing_utils                 # ì–¼êµ´ì— ê·¸ë¦¬ëŠ” ê¸°ëŠ¥
        mp_drawing_styles = mp.solutions.drawing_styles         # ê·¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ ì…‹ ê°€ì ¸ì˜´
        cv2.namedWindow("Face Mesh View", cv2.WINDOW_NORMAL)    # "Face Mesh View" ì°½ ì—´ê¸°

    cv2.namedWindow("Gaze Estimation", cv2.WINDOW_NORMAL)       # "Gaze Estimation" ì°½ ì—´ê¸°

    calibration_step = 0            # í˜„ì¬ ë³´ì • ì¤‘ì¸ ì½”ë„ˆ
    calibration_complete = False    # ë³´ì • ì™„ë£Œ ì—¬ë¶€
    calibration_points = []         # ìˆ˜ì§‘ëœ ëˆˆ ìœ„ì¹˜ ì €ì¥

    open_ref = None # ëˆˆ ë– ìˆëŠ” ê¸°ì¤€ ì ìš©
    was_closed = False
    calibration_eye_open_list = []

    margin = 50         # ëª¨ì„œë¦¬ ì¢Œí‘œ ê¸°ì¤€
    corner_points = [
        (margin, margin),  # top-left
        (screen_w - margin, margin),  # top-right
        (margin, screen_h - margin),  # bottom-left
        (screen_w - margin, screen_h - margin)  # bottom-right
    ]
    instructions = [    # ê° ëª¨ì„œë¦¬ ì•ˆë‚´
        "Look at top-left corner and press 'w'",
        "Look at top-right corner and press 'w'",
        "Look at bottom-left corner and press 'w'",
        "Look at bottom-right corner and press 'w'"
    ]

    def draw_cross(img, center, size=20, color=(0, 0, 0), thickness=2): # í™”ë©´ì— í‘œì‹œí•  ì‹­ìê°€ë¥¼ ê·¸ë¦¬ëŠ” ì½”ë“œ
        cx, cy = center
        half = size // 2
        cv2.line(img, (cx - half, cy), (cx + half, cy), color, thickness)
        cv2.line(img, (cx, cy - half), (cx, cy + half), color, thickness)

    # ë³´ê°„ìš© ì´ˆê¸°í™”
    prev_x, prev_y = None, None
    alpha = 0.5 # ë¶€ë“œëŸ¬ì›€ ì •ë„ (0.1 ~ 0.3 ì¶”ì²œ)

    # Blink ì •ë³´
    blink_frame_count = 0   # ëˆˆì„ ì—°ì†ìœ¼ë¡œ ê°ì€ í”„ë ˆì„ ìˆ˜
    blink_threshold = 4     # ëˆˆ ê°ì€ ìƒíƒœ ê¸°ì¤€
    blinked_count = 0       # ì´ ëˆˆ ê°ì€ íšŸìˆ˜
    bBlink = 0              # Unreal ì „ì†¡ìš© ìƒíƒœê°’

    while True:
        if stop_event and stop_event.is_set():  # Stop eventê°€ ì‹¤í–‰ë˜ë©´
            print("stop_event ë¥¼ í†µí•œ ë£¨í”„ ì¢…ë£Œ")
            break                               # ì¢…ë£Œ

        ret, frame = cap.read()                 # ret = í”„ë ˆì„ ì •ìƒì ìœ¼ë¡œ ì½ì—ˆëŠ”ì§€ ì—¬ë¶€, frame = ì˜ìƒë°ì´í„°
        if not ret:                             # ì •ìƒì ìœ¼ë¡œ ëª» ì½ìœ¼ë©´
            break                               # ì¢…ë£Œ

        frame = cv2.flip(frame, 1)              # frame ì˜ ì´ë¯¸ì§€ë¥¼ ì¢Œìš° ë°˜ì „
        face_mesh_frame = frame.copy() if show_face_mesh else None  # ë©”ì‰¬ë¥¼ ë³¸ë‹¤ë©´, frameì„ ë³µì‚¬í•˜ì—¬ ì €ì¥
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # BGRì„ RGBë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        results = face_mesh.process(rgb_frame)              # rgb_frameë¥¼ ì‚¬ì „ì— ì •ë¦¬í•œ MPëª¨ë¸ì— ë„£ì€ ê±¸ resultì— ì‘ì—…
        screen = np.ones((screen_h, screen_w, 3), dtype=np.uint8) * 255
        # screenì€ ê°€ë¡œ, ì„¸ë¡œ, 3ì±„ë„ì— 1ì„ ë„£ê³ , íƒ€ì…ì€ ë„˜íŒŒì´ unit8ì¸ë°, ì—¬ê¸° 255ë¥¼ ê³±í•¨(í°ìƒ‰)

        if results.multi_face_landmarks:    # resultì— ì–¼êµ´ ì£¼ìš”ì§€í‘œê°€ ë“¤ì–´ê°„ë‹¤ë©´
            for face_landmarks in results.multi_face_landmarks:     # ê° ì–¼êµ´ ì§€í‘œë³„ë¡œ
                left_eye_top = face_landmarks.landmark[159].y       # ì™¼ìª½ ìœ„ ëˆˆêº¼í’€
                left_eye_bottom = face_landmarks.landmark[145].y    # ì™¼ìª½ ì•„ë˜ ëˆˆêº¼í’€
                forehead_y = face_landmarks.landmark[10].y
                chin_y = face_landmarks.landmark[152].y
                face_height = abs(chin_y - forehead_y)
                eye_openness = abs(left_eye_bottom - left_eye_top)  # ëˆˆ ë–³ëŠ”ì§€ ì—¬ë¶€
                eye_openness_normalized = eye_openness / face_height

                #ëˆˆ ê¹œë¹¡ì„
                if open_ref is not None and eye_openness_normalized < open_ref * 0.5 :
                    blink_frame_count +=1       # í”„ë ˆì„ ì¹´ìš´íŠ¸ ì¶”ê°€
                    if blink_frame_count >= blink_threshold:
                        bBlink = 1              # ê°ì€ ìƒíƒœ
                        was_closed = True     # ê°ì€ íšŸìˆ˜
                else:
                    if was_closed:
                        blinked_count +=1
                        was_closed = False
                    blink_frame_count = 0       # í”„ë ˆì„ ì¹´ìš´íŠ¸
                    bBlink = 0                  # ê°ì€ ìƒíƒœ

                if open_ref is not None:
                    print(f"left_top :{left_eye_top:.4f}, left_bottom :{left_eye_bottom:.5f}, eye_openness_normalized: {eye_openness_normalized:.5f}, open_ref: {open_ref:.4f} bBlink: {bBlink}, frame_count: {blink_frame_count}")
                else:
                    print(f"left_top :{left_eye_top:.4f}, left_bottom :{left_eye_bottom:.5f}, eye_openness_normalized: {eye_openness_normalized:.5f}, bBlink: {bBlink}, frame_count: {blink_frame_count}")
                
                if show_face_mesh and face_mesh_frame is not None:  # ë©”ì‰¬ë¥¼ ë°›ê¸°ë¡œ í–ˆê³ , ë“¤ì–´ì˜¨ë‹¤ë©´
                    mp_drawing.draw_landmarks(      # ì£¼ìš” ì§€ì ì—ì„œ ì´í•˜ë¥¼ mp_drawingì— ë„£ëŠ”ë‹¤
                        image=face_mesh_frame,      # ê·¸ë¦¼ ê·¸ë¦´ ëŒ€ìƒì€ ì–¼êµ´í”„ë ˆì„
                        landmark_list=face_landmarks,   # ì£¼ìš” ì§€ì  ë¦¬ìŠ¤íŠ¸ = ì–¼êµ´ ì£¼ìš” ì§€ì 
                        connections=mp_face_mesh.FACEMESH_TESSELATION,  # ì—°ê²°(ì„ ) = ì–¼êµ´ ë©”ì‰¬ ì¤‘ í…Œì…€ë ˆì´ì…˜(ê²¹ì¹˜ì§€ ì•Šê²Œ ê³µê°„ ì±„ì›€)
                        landmark_drawing_spec=None, #ëœë“œë§ˆí¬(ì )ë¥¼ ì–´ë–»ê²Œ ê·¸ë¦´ì§€ = ê¸°ë³¸
                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()
                    )   # ì„  ì–´ë–»ê²Œ ê·¸ë¦´ì§€ = mpìŠ¤íƒ€ì¼ì—ì„œ ê¸°ë³¸ í…Œì…€ë ˆì´ì…˜ ìŠ¤íƒ€ì¼
                    mp_drawing.draw_landmarks(      #ì£¼ìš” ì§€ì ì—ì„œ ì´í•˜ë¥¼ mp_drawingì— ê°€ì ¸ê°„ë‹¤
                        image=face_mesh_frame,      # ê·¸ë¦´ ëŒ€ìƒ = ì–¼êµ´ í”„ë ˆì„
                        landmark_list=face_landmarks,   # ì£¼ìš” ì§€ì  ë¦¬ìŠ¤íŠ¸ = ì–¼êµ´ ì£¼ìš” ì§€ì 
                        connections=mp_face_mesh.FACEMESH_IRISES,   # ì„ ë“¤ = mp_ì–¼êµ´ ë©”ì‰¬ì—ì„œ í™ì±„
                        landmark_drawing_spec=None, # ì£¼ìš” ì§€ì (ì ) ê·¸ë¦¬ëŠ” ì„¤ì • = ê¸°ë³¸
                        connection_drawing_spec=mp_drawing.DrawingSpec(color=(0,255,0), thickness=1)
                    )   # ì„  ì–´ë–»ê²Œ ê·¸ë¦´ì§€ = mpìŠ¤íƒ€ì¼ì—ì„œ ì´ ìƒ‰ìœ¼ë¡œ ê·¸ë ¤ë¼
                left_iris = face_landmarks.landmark[468]    # ì™¼ìª½ í™ì±„ = ì£¼ìš”ì§€í‘œ ì¤‘ 468ë²ˆ
                right_iris = face_landmarks.landmark[473]   # ì˜¤ë¥¸ìª½ í™ì±„ = ì£¼ìš”ì§€í‘œ ì¤‘ 473ë²ˆ
                nose_tip = face_landmarks.landmark[1]       # ì½” ë(ê¸°ì¤€ì ) = ì–¼êµ´ ì£¼ìš”ì§€í‘œ ì¤‘ 1ë²ˆ

                eye_x = (left_iris.x + right_iris.x) / 2    # ëˆˆë™ì ì‹œì„  ì¤‘ xì¢Œí‘œ ì¤‘ê°„ê°’
                eye_y = (left_iris.y + right_iris.y) / 2    # ëˆˆë™ì ì‹œì„  ì¤‘ yì¢Œí‘œ ì¤‘ê°„ê°’

                dx = eye_x - nose_tip.x     # ì‹œì„  ì¢Œìš° ìƒëŒ€ì¢Œí‘œ (ì½”ë ê¸°ì¤€ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ê°€)
                dy = eye_y - nose_tip.y     # ì‹œì„  ìƒí•˜ ìƒëŒ€ì¢Œí‘œ (ì½”ë ê¸°ì¤€...)

                gaze_x = int((0.5 + dx * 5) * screen_w) # ìƒëŒ€ì¢Œí‘œë¥¼ í‚¤ìš°ê³ (*5) 0.5(ê°€ìš´ë°)ë¥¼ ë”í•¨, ìƒëŒ€ì¢Œí‘œê°€ ìŒìˆ˜ë©´ ë‚˜ê°€ë²„ë¦¬ë‹ˆê¹Œ
                gaze_y = int((0.5 + dy * 5) * screen_h) # ìƒëŒ€ì¢Œí‘œë¥¼ í‚¤ìš°ê³  ê°€ìš´ë° ìœ„ì¹˜ë¥¼ ì§€ì •. ê°€ìš´ë° ê¸°ë°˜ìœ¼ë¡œ ìœ ë„

                gaze_x = np.clip(gaze_x, 0, screen_w - 1)   # ìë¥´ê¸°(í˜„ì¬ê°’, ìµœì†Œê°’, ìµœëŒ€ê°’)
                gaze_y = np.clip(gaze_y, 0, screen_h - 1)   # ìë¥´ê¸°(í˜„ì¬ê°’, ìµœì†Œê°’, ìµœëŒ€ê°’)

                if not calibration_complete:    # ì¹¼ë¦¬ë¸Œë ˆì´ì…˜ì´ ì•ˆëœë‹¤ë©´
                    if calibration_step < 4:    # ì•„ì§ ì§„í–‰ ì¤‘ ì´ë¼ë©´
                        # ë³´ì •ìš© ì‹­ì í‘œì‹œ
                        draw_cross(screen, corner_points[calibration_step], 30, (0, 0, 255), 2)
                        # ì‹­ìê°€ë¥¼ ê·¸ë¦°ë‹¤(ë°°ê²½ì—, ì§€ì •í•œ ì½”ë„ˆí¬ì¸íŠ¸[ê° ìˆœì„œ], í¬ê¸°, ìƒ‰, ë‘ê»˜(-1 = ì±„ìš´ë‹¤))
                        font = cv2.FONT_HERSHEY_SIMPLEX                     # í°íŠ¸
                        text = instructions[calibration_step]               # ì–´ë–¤ ë¬¸êµ¬? = ìœ„ì— ì§€ì •í•œ ë¬¸êµ¬(í˜ì´ì§€ ë³„)
                        (tw, th), _ = cv2.getTextSize(text, font, 0.8, 2)   # í…ìŠ¤íŠ¸ ê°€ë¡œ, ì„¸ë¡œ, ìµœì € ë†’ì´ = í…ìŠ¤íŠ¸ í¬ê¸°(ë‚´ìš©, í°íŠ¸, í¬ê¸°, ë‘ê»˜ )
                        tx = (screen_w - tw) // 2   # í…ìŠ¤íŠ¸ ê°€ë¡œ ì¢Œí‘œ
                        ty = screen_h // 2          # í…ìŠ¤íŠ¸ ì„¸ë¡œ ì¢Œí‘œ
                        cv2.putText(screen, text, (tx, ty), font, 0.8, (0, 0, 0), 2)
                        # í…ìŠ¤íŠ¸ë¥¼ ê·¸ë ¤ë¼(ë°°ê²½ì—, ê¸€ìë¥¼, ìœ„ì¹˜, í°íŠ¸, í¬ê¸°, ìƒ‰ìƒ, ë‘ê»˜)
                else:   # ì¹¼ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ ë«ë‹¤ë©´
                    # ëˆˆ ìœ„ì¹˜ë¥¼ ë³´ì •ëœ í™”ë©´ ì¢Œí‘œë¡œ ë§¤í•‘
                    xs, ys = zip(*calibration_points)   # ëˆˆ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸ë¥¼ unpack
                    min_x, max_x = min(xs), max(xs)     # ìµœì†Œ ìµœëŒ€ xì¢Œí‘œ ìœ„ì¹˜ê°’
                    min_y, max_y = min(ys), max(ys)     # ìµœì†Œ ìµœëŒ€ yì¢Œí‘œ ìœ„ì¹˜ê°’

                    range_x = max_x - min_x # ë²”ìœ„ = ìµœëŒ€ê°’ - ìµœì†Œê°’
                    range_y = max_y - min_y # ë²”ìœ„ = ìµœëŒ€ê°’ - ìµœì†Œê°’

                    dx = eye_x  # dx = ëˆˆ x ì¢Œí‘œ
                    dy = eye_y  # dy = ëˆˆ y ì¢Œí‘œ

                    if range_x == 0 or range_y == 0: #ë§Œì•½ ë²”ìœ„ê°€ 0ì´ë¼ë©´
                        mapped_x, mapped_y = screen_w // 2, screen_h // 2
                        # ìµœì¢… ìœ„ì¹˜ = í™”ë©´ ê°€ìš´ë°
                    else:   #rangeê°€ 0ì´ ì•„ë‹ˆë¼ë©´
                        mapped_x = int((dx - min_x) / range_x * screen_w)
                        mapped_y = int((dy - min_y) / range_y * screen_h)
                        # ê° ê°’ = (ëˆˆ ì¢Œí‘œ - ìµœì†Œê°’) / x ë²”ìœ„ * ì „ì²´ ë„ˆë¹„(ë†’ì´)

                    mapped_x = np.clip(mapped_x, 0, screen_w - 1)
                    mapped_y = np.clip(mapped_y, 0, screen_h - 1)
                        # ë§Œì•½ì— ë³´ì €ì˜¤ë”˜ í¬ê¸°ê°€ ë„˜ìœ¼ë©´ ì˜ë¼

                    if prev_x is not None and prev_y is not None:   #ì²˜ìŒ ì‹œì‘í•  ë•Œ ì´ì „ ì¢Œí‘œê°€ ì—†ê¸° ë•Œë¬¸ì—, ìˆì„ ë•Œì—ë§Œ ì‹¤í–‰
                        mapped_x = int(alpha * mapped_x + (1 - alpha) * prev_x) #ì¢Œí‘œ = ì¡°ì •ê°’ * ìœ„ì¹˜ + (1-ì¡°ì •ê°’) * ì´ì „ ê°’
                        mapped_y = int(alpha * mapped_y + (1 - alpha) * prev_y) 

                    prev_x, prev_y = mapped_x, mapped_y     # ì´ì „ ê°’ = í˜„ì¬ ê°’

                    cv2.circle(screen, (mapped_x, mapped_y), 20, (0, 0, 255), -1)
                    blink_text = f"Closed Count: {blinked_count}"
                    cv2.putText(screen, blink_text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)

                    # ì›ì„ ê·¸ë ¤ë¼, í™”ë©´ì—, ì¢Œí‘œ, í¬ê¸°, ìƒ‰, ë‘ê¼(ì±„ìš´ë‹¤)
                    if not stop_event.is_set():     # ì•ˆë©ˆì¶”ë©´
                        q.put({
                            "type": "response",
                            "data": {
                                "quiz_id": 1,
                                "screen_w": screen_w,
                                "screen_h": screen_h,
                                "x": mapped_x,
                                "y": mapped_y,
                                "blink": bBlink,
                                "state": 100
                            }
                        })

        key = cv2.waitKey(1) & 0xFF # keyëŠ” 1ë°€ë¦¬ì´ˆë™ì•ˆ ê¸°ë‹¤ë¦¬ê³  8ë¹„íŠ¸(ASCII) ë§ˆìŠ¤í‚¹ í•¨
        if key == ord('w') and not calibration_complete and calibration_step < 4:
            # wë¥¼ ëˆŒë €ê³ , ì¹¼ë¦¬ë¸Œë ˆì´ì…˜ì´ ì•ˆëë‚¬ë‹¤ë©´
            calibration_points.append((eye_x, eye_y))   # ì¹¼ë¦¬ë¸Œë ˆì´ì…˜ í¬ì¸íŠ¸ì— ëˆˆ ìœ„ì¹˜ ì¶”ê°€
            calibration_eye_open_list.append(eye_openness_normalized)
            calibration_step += 1   # ë‹¨ê³„ì— 1 ì¶”ê°€
            if calibration_step == 4:   # ë§Œì•½ ë‹¨ê³„ê°€ ë‹¤ ë˜ì—ˆë‹¤ë©´
                open_ref = np.mean(calibration_eye_open_list)
                calibration_complete = True #ì¹¼ë¦¬ë¸Œë ˆì´ì…˜ ë 

        if key == ord('q'): # qëˆ„ë¥´ë©´
            if stop_event is not None:  # stop_eventê°€ ë“¤ì–´ì˜¤ë©´
                print("ğŸ›‘ Gaze Estimation ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡")  # ì¶œë ¥
                stop_event.set()        # stop_event ì‹¤í–‰
            break# ì¢…ë£Œ

        cv2.imshow("Gaze Estimation", screen)   #"Gaze..." ì´ë¼ëŠ” ìŠ¤í¬ë¦°ì„ ì¼œì¤˜
        if show_face_mesh and face_mesh_frame is not None:
            # ë§Œì•½ ì–¼êµ´ë©”ì‰¬ê°€ ì¼œì ¸ìˆë‹¤ë©´
            cv2.imshow("Face Mesh View", face_mesh_frame)
            # ì–¼êµ´ ë³´ê¸° ë¥¼ face_meshë¥¼ Face_Mesh...ë¡œ ì‚½ì…

    cap.release()   # ìº¡ì³ ë©ˆì¶°
    cv2.destroyAllWindows() # ëª¨ë“  ì°½ ì¢…ë£Œ